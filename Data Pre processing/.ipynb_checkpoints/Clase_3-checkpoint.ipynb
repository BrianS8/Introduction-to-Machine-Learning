{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h1> <center> Manejo de Bases de Datos </center> </h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Archivos </h2>\n",
    "\n",
    "<p> De acuerdo a la documentación de <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/io.html\"> Pandas</a> es posible importar distintos tipos de archivos, por ejemplo:</p>\n",
    "<ul>\n",
    "    <li> Archivos planos: Son archivos compuestos por caracteres sin formato, por lo general son los archivos .txt </li>\n",
    "    <li> Archivos .csv o .tsv: Son archivos en los que las filas estan separadas por espacios tabulados, y las columans por comas </li>\n",
    "</ul>\n",
    "<br></br>\n",
    "<b> Nota: </b> Muchas de las bases de datos que trabajaremos de aquí en adelantes se encuentran en los repositorios de <a href=\"http://mlr.cs.umass.edu/ml/\"> UCI</a> y <a href=\"https://www.quandl.com\"> QUANDL</a>, entre otros que en su oportunidad iremos comentando\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl as oxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## En este caso importaremos un archivo Excel y un archivo csv\n",
    "df   = pd.read_excel('mpg.xlsx','HojaDatos')\n",
    "data = pd.read_csv('mpg.csv', sep = \";\")\n",
    "print(df.head(), \"\\n\\n\\n\")\n",
    "print(df.dtypes, \"\\n\\n\\n\")\n",
    "print(data.head(), \"\\n\\n\\n\")\n",
    "print(df.dtypes, \"\\n\\n\\n\")\n",
    "#dir(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos transformar el tipo de campo que tiene nuestra base de datos, por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"horsepower\"].astype(str)\n",
    "print(df.dtypes, \"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"horsepower\"].astype(float)\n",
    "df['horsepower'] = pd.to_numeric(df['horsepower'], errors='coerce')\n",
    "print(df.dtypes, \"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Limpieza de bases de datos </h2>\n",
    "<br></br>\n",
    "<p>Por lo general, la limpieza se centra en trabajar con los datos vacíos, y es que en ocasiones las fuentes de información vienen incompletas por múltiples causas, por ejemplo: problemas de digitalización, problemas de ETL, entre otras razones.</p>\n",
    "\n",
    "<p>En los siguientes casos vamos a tener una submuestra de la base <i>mpg</i> en la cual va a presentar los siguientes casos:</p>\n",
    "<ul>\n",
    "    <li> Valores pérdidos estándar </li>\n",
    "    <li> Valores pérdidos no estándar </li>\n",
    "    <li> Valores inesperados </li>\n",
    "</ul>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df   = pd.read_excel('mpg_clean.xlsx')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Identificar los missing values\n",
    "mv = ['na','--','n/a']\n",
    "df   = pd.read_excel('mpg_clean.xlsx', na_values= mv)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de valores pérdidos\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Existen distintas formas de reemplazar los valores pérdidos, podemos reemplazarlos con el valor de la media, mediana o moda, para datos númericos, moda para datos string o categóricos, o eliminar el registro </p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null1 = df['displacement'].mean()\n",
    "null2 = df['horsepower'].median()\n",
    "null3 = df['weight'].median()\n",
    "null4 = df['model year'].mean()\n",
    "null5 = df['acceleration'].median()\n",
    "null6 = int(df['origin'].mode())\n",
    "\n",
    "print('\\n',null1,null2,null3,null4,null5,null6,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['displacement'].fillna(null1, inplace = True)\n",
    "df['horsepower'].fillna(null2, inplace = True)\n",
    "df['weight'].fillna(null3, inplace = True)\n",
    "df['model year'].fillna(null4, inplace = True)\n",
    "df['acceleration'].fillna(null5, inplace = True)\n",
    "df['origin'].fillna(null6, inplace = True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Si revisamos, la variable <i>cylinders</i> presenta un error, y es que en la primera posición poseen caracteres alfabéticos, para ello debemos realizar una transformación adicional</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cylinders'] = df['cylinders'].map(lambda x: x.lstrip('aAbBcCdvpft'))\n",
    "df['cylinders']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Si revisamos el campo de <i> car name </i> encontramos que hay registros numéricos que no son coherentes con el registro, por tanto, al ser la \"llave\", tenemos que eliminar el registro</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['car name'])\n",
    "df = df.drop([18, 24])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['car name'].unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Consultas </h2>\n",
    "<p> Al poseer grandes fuentes de información, es necesario aplicar ciertas funciones sobre nuestras bases de datos que nos permitan visualizar:</p>\n",
    "<ul>\n",
    "    <li> Llave única</li>\n",
    "    <li> Medidas de tendencia de un campo </li>\n",
    "    <li> Total de un campo</li>\n",
    "    <li> Ordenar la base de datos </li>\n",
    "    <li> Eliminar duplicados </li>\n",
    "    <li> Contar valores únicos </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes, \"\\n\\n\\n\")\n",
    "df['cylinders'] = pd.to_numeric(df['cylinders'], errors='coerce')\n",
    "print(df.dtypes, \"\\n\\n\\n\")\n",
    "print('\\n SUMA \\n\\n',df.apply(np.sum),'\\n\\n')\n",
    "print('\\n MEDIA \\n\\n',df.iloc[:,0:8].apply(np.mean),'\\n\\n')\n",
    "print('\\n MEDIANA \\n\\n',df.iloc[:,0:8].apply(np.median),'\\n\\n')\n",
    "print('\\n MODA \\n\\n',df['car name'].mode(),'\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambien es posible ordenar la base de datos, y eliminar aquellos registros que esten duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar la base de datos\n",
    "print('\\n ORDENAR POR AÑO \\n\\n',df.sort_values(by=['model year'], ascending=False),'\\n\\n')\n",
    "print('\\n ORDENAR POR AÑO Y PESO \\n\\n',df.sort_values(by=['model year','weight']),'\\n\\n')\n",
    "print('\\n ¿HAY DUPLICADOS? \\n\\n',df.duplicated(),'\\n\\n')\n",
    "print('\\n ELIMINAR DUPLICADOS \\n\\n',df.drop_duplicates(),'\\n\\n')\n",
    "print('\\n ELIMINAR DUPLICADOS POR COLUMNAS \\n\\n',df.drop_duplicates(['mpg']),'\\n\\n')\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos contar valores únicos, de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n\\n CONTAR VALORES ÚNICOS \\n\\n',df.nunique(),'\\n\\n')\n",
    "print('\\n\\n CONTAR VALORES ÚNICOS \\n\\n',df.count(),'\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Combinar, unir y concatenar </h2>\n",
    "<br></br>\n",
    "<p> En el momento de manejar distintas bases de datos, es importante conocer como podemos obtener información de cada una de ellas</p>\n",
    "<p> En esta sección veremos como combinar, unir y concatenar bases de datos </p>\n",
    "<ul>\n",
    "    <li> Para concatenar un marco de datos, utilizamos la función .concat(), esta función concatena un marco de datos y devuelve un nuevo marco de datos</li>\n",
    "    <li> Para concatenar un marco de datos, utilizamos la función .append() esta función concatena a lo largo del eje = 0, es decir, el índice. </li>\n",
    "    <li> Para juntar bases de datos utilizamos la función .merge()</li>\n",
    " </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Para estos ejercicios tomaremos tres tipos de bases diferentes que nos permitan combinar, unir y juntar. También ubicaremos la llave </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(301, 9)\n",
      "\n",
      "\n",
      " CONTAR VALORES ÚNICOS \n",
      "\n",
      " mpg             109\n",
      "cylinders         5\n",
      "displacement     77\n",
      "horsepower       87\n",
      "weight          275\n",
      "acceleration     90\n",
      "model year       13\n",
      "origin            3\n",
      "car name        301\n",
      "dtype: int64 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " CONTAR VALORES ÚNICOS \n",
      "\n",
      " mpg             301\n",
      "cylinders       301\n",
      "displacement    301\n",
      "horsepower      301\n",
      "weight          301\n",
      "acceleration    301\n",
      "model year      301\n",
      "origin          301\n",
      "car name        301\n",
      "dtype: int64 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Bases de datos\n",
    "df = pd.read_excel('mpg.xlsx','HojaDatos')\n",
    "print(df.shape)\n",
    "# Separar en subconjuntos de índices\n",
    "df1 = df.iloc[0:199]\n",
    "df2 = df.iloc[200:298]\n",
    "# Separar en columnas\n",
    "df3 = df.iloc[0:10,[0,1,2,3,4,8]]\n",
    "df4 = df.iloc[0:13,[5,6,7,8]]\n",
    "print('\\n\\n CONTAR VALORES ÚNICOS \\n\\n',df.nunique(),'\\n\\n')\n",
    "print('\\n\\n CONTAR VALORES ÚNICOS \\n\\n',df.count(),'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 9) \n",
      "\n",
      "\n",
      "            mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
      "train 0    18.0          8         307.0       130.0    3504          12.0   \n",
      "      1    15.0          8         350.0       165.0    3693          11.5   \n",
      "      2    18.0          8         318.0       150.0    3436          11.0   \n",
      "      3    16.0          8         304.0       150.0    3433          12.0   \n",
      "      4    17.0          8         302.0       140.0    3449          10.5   \n",
      "...         ...        ...           ...         ...     ...           ...   \n",
      "test  296  27.0          4         140.0        86.0    2790          15.6   \n",
      "      297  44.0          4          97.0        52.0    2130          24.6   \n",
      "      298  32.0          4         135.0        84.0    2295          11.6   \n",
      "      299  28.0          4         120.0        79.0    2625          18.6   \n",
      "      300  31.0          4         119.0        82.0    2720          19.4   \n",
      "\n",
      "           model year  origin                     car name  \n",
      "train 0            70       1  \"chevrolet chevelle malibu\"  \n",
      "      1            70       1          \"buick skylark 320\"  \n",
      "      2            70       1         \"plymouth satellite\"  \n",
      "      3            70       1              \"amc rebel sst\"  \n",
      "      4            70       1                \"ford torino\"  \n",
      "...               ...     ...                          ...  \n",
      "test  296          82       1            \"ford mustang gl\"  \n",
      "      297          82       2                  \"vw pickup\"  \n",
      "      298          82       1              \"dodge rampage\"  \n",
      "      299          82       1                \"ford ranger\"  \n",
      "      300          82       1                 \"chevy s-10\"  \n",
      "\n",
      "[300 rows x 9 columns] \n",
      "\n",
      "\n",
      "(300, 9)\n"
     ]
    }
   ],
   "source": [
    "# Concatenación\n",
    "df5 = pd.concat([df1,df2]) # , ignore_index=True\n",
    "df6 = pd.concat([df1,df2],keys=['train', 'test'])\n",
    "print(df5.shape,'\\n\\n')\n",
    "print(df6,'\\n\\n')\n",
    "\n",
    "df5 = df1.append(df2)\n",
    "print(df5.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Uniones </h3>\n",
    "<p> Las uniones consisten en combinaciones de dos bases de datos con el uso de una llave, que por buena práctica, en al menos una de las bases debe ser única. </p> \n",
    "<p> Con este tipo de acciones podemos agregar información, buscar información relevante y estructurar los datos </p>\n",
    "<br></br>\n",
    "<img src= 'merge.png',width=400,heigth=1000, alt=\"Flowers in Chania\">\n",
    "<center> <i> Imagen tomada de <a href=\"https://www.geeksforgeeks.org/python-pandas-merging-joining-and-concatenating/\"> geeksforgeeks</a> </i></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union1 = pd.merge(df3, df4, on='car name')\n",
    "union1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union2 = pd.merge(df3, df4, how='left', on=['car name'])\n",
    "union3 = pd.merge(df3, df4, how='right',  on=['car name'])\n",
    "union4 = pd.merge(df3, df4, how='inner',  on=['car name'])\n",
    "union5 = pd.merge(df3, df4, how='outer',  on=['car name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Exportar base </h3>\n",
    "<p>Al trabajar con bases de datos, en muchas ocasiones necesitamos exportar los resultados para utilizarla en otros entornos, por espacio, por eficiencia, o por otros criterios.</p>\n",
    "<p> En este caso exportaremos la base de datos en 3 escenarios: </p>\n",
    "<ul>\n",
    "    <li> .txt </li>\n",
    "    <li> .csv </li>\n",
    "    <li> .xlsx </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"mpg1.xlsx\", \"Sheet1\")\n",
    "df.to_csv(\"mpg1.csv\")\n",
    "df.to_csv(\"mpg1.txt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
