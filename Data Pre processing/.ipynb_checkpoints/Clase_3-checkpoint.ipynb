{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h1> <center> Manejo de Bases de Datos </center> </h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Archivos </h2>\n",
    "\n",
    "<p> De acuerdo a la documentación de <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/io.html\"> Pandas</a> es posible importar distintos tipos de archivos, por ejemplo:</p>\n",
    "<ul>\n",
    "    <li> Archivos planos: Son archivos compuestos por caracteres sin formato, por lo general son los archivos .txt </li>\n",
    "    <li> Archivos .csv o .tsv: Son archivos en los que las filas estan separadas por espacios tabulados, y las columans por comas </li>\n",
    "</ul>\n",
    "<br></br>\n",
    "<b> Nota: </b> Muchas de las bases de datos que trabajaremos de aquí en adelantes se encuentran en los repositorios de <a href=\"http://mlr.cs.umass.edu/ml/\"> UCI</a> y <a href=\"https://www.quandl.com\"> QUANDL</a>, entre otros que en su oportunidad iremos comentando\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl as oxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## En este caso importaremos un archivo Excel y un archivo csv\n",
    "df   = pd.read_excel('mpg.xlsx','HojaDatos')\n",
    "data = pd.read_csv('mpg.csv', sep = \";\")\n",
    "print(df.head(), \"\\n\\n\\n\")\n",
    "print(df.dtypes, \"\\n\\n\\n\")\n",
    "print(data.head(), \"\\n\\n\\n\")\n",
    "print(df.dtypes, \"\\n\\n\\n\")\n",
    "#dir(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos transformar el tipo de campo que tiene nuestra base de datos, por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"horsepower\"].astype(str)\n",
    "print(df.dtypes, \"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"horsepower\"].astype(float)\n",
    "df['horsepower'] = pd.to_numeric(df['horsepower'], errors='coerce')\n",
    "print(df.dtypes, \"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Limpieza de bases de datos </h2>\n",
    "<br></br>\n",
    "<p>Por lo general, la limpieza se centra en trabajar con los datos vacíos, y es que en ocasiones las fuentes de información vienen incompletas por múltiples causas, por ejemplo: problemas de digitalización, problemas de ETL, entre otras razones.</p>\n",
    "\n",
    "<p>En los siguientes casos vamos a tener una submuestra de la base <i>mpg</i> en la cual va a presentar los siguientes casos:</p>\n",
    "<ul>\n",
    "    <li> Valores pérdidos estándar </li>\n",
    "    <li> Valores pérdidos no estándar </li>\n",
    "    <li> Valores inesperados </li>\n",
    "</ul>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     mpg cylinders  displacement  horsepower weight  acceleration  model year  \\\n",
      "0   18.0        c8         307.0       130.0   3504          12.0        70.0   \n",
      "1   15.0        b8         350.0       165.0   3693          11.5        70.0   \n",
      "2   18.0        p8         318.0       150.0   3436          11.0        70.0   \n",
      "3   16.0        a8         304.0       150.0   3433          12.0        70.0   \n",
      "4   17.0        f8         302.0       140.0   3449          10.5        70.0   \n",
      "5   15.0        f8         429.0         NaN   4341          10.0        70.0   \n",
      "6   14.0        c8         454.0       220.0   4354           9.0        70.0   \n",
      "7   14.0        p8         440.0       215.0   4312           NaN         NaN   \n",
      "8   14.0        p8         455.0       225.0   4425          10.0        70.0   \n",
      "9   15.0        a8         390.0       190.0   3850           8.5        70.0   \n",
      "10  15.0        d8         383.0       170.0   3563          10.0        70.0   \n",
      "11  14.0        p8         340.0       160.0   3609           8.0        70.0   \n",
      "12  15.0        c8           NaN       150.0   3761           9.5        70.0   \n",
      "13  14.0        b8         455.0       225.0   3086          10.0        70.0   \n",
      "14  24.0        t4         113.0        95.0   2372          15.0         NaN   \n",
      "15  22.0        p6         198.0        95.0   2833          15.5        70.0   \n",
      "16  18.0        a6         199.0        97.0   2774           NaN        70.0   \n",
      "17  21.0        f6         200.0        85.0     na          16.0        70.0   \n",
      "18  27.0        d4          97.0        88.0   2130          14.5        70.0   \n",
      "19  26.0        v4          97.0        46.0   1835          20.5        70.0   \n",
      "20  25.0        p4         110.0        87.0   2672          17.5        70.0   \n",
      "21  22.0        p6         198.0        95.0   2833          15.5        70.0   \n",
      "22  18.0        a6         199.0        97.0   2774           NaN        70.0   \n",
      "23  21.0        f6         200.0        85.0     na          16.0        70.0   \n",
      "24  27.0        d4          97.0        88.0   2130          14.5        70.0   \n",
      "25  26.0        v4          97.0        46.0   1835          20.5        70.0   \n",
      "26  25.0        p4         110.0        87.0   2672          17.5        70.0   \n",
      "\n",
      "   origin                        car name  \n",
      "0       1     \"chevrolet chevelle malibu\"  \n",
      "1       1             \"buick skylark 320\"  \n",
      "2       1            \"plymouth satellite\"  \n",
      "3       1                 \"amc rebel sst\"  \n",
      "4       1                   \"ford torino\"  \n",
      "5       1              \"ford galaxie 500\"  \n",
      "6       1              \"chevrolet impala\"  \n",
      "7       1             \"plymouth fury iii\"  \n",
      "8       1              \"pontiac catalina\"  \n",
      "9       1            \"amc ambassador dpl\"  \n",
      "10      1           \"dodge challenger se\"  \n",
      "11      1            \"plymouth 'cuda 340\"  \n",
      "12      1         \"chevrolet monte carlo\"  \n",
      "13      1       \"buick estate wagon (sw)\"  \n",
      "14      3         \"toyota corona mark ii\"  \n",
      "15      1               \"plymouth duster\"  \n",
      "16     --                    \"amc hornet\"  \n",
      "17      1                 \"ford maverick\"  \n",
      "18      3                              12  \n",
      "19      2  \"volkswagen 1131 deluxe sedan\"  \n",
      "20      2                   \"peugeot 504\"  \n",
      "21      1               \"plymouth duster\"  \n",
      "22     --                    \"amc hornet\"  \n",
      "23      1                 \"ford maverick\"  \n",
      "24      3                              12  \n",
      "25      2  \"volkswagen 1131 deluxe sedan\"  \n",
      "26      2                   \"peugeot 504\"  \n"
     ]
    }
   ],
   "source": [
    "df   = pd.read_excel('mpg_clean.xlsx')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Identificar los missing values\n",
    "mv = ['na','--','n/a']\n",
    "df   = pd.read_excel('mpg_clean.xlsx', na_values= mv)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de valores pérdidos\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Existen distintas formas de reemplazar los valores pérdidos, podemos reemplazarlos con el valor de la media, mediana o moda, para datos númericos, moda para datos string o categóricos, o eliminar el registro </p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null1 = df['displacement'].mean()\n",
    "null2 = df['horsepower'].median()\n",
    "null3 = df['weight'].median()\n",
    "null4 = df['model year'].mean()\n",
    "null5 = df['acceleration'].median()\n",
    "null6 = int(df['origin'].mode())\n",
    "\n",
    "print('\\n',null1,null2,null3,null4,null5,null6,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['displacement'].fillna(null1, inplace = True)\n",
    "df['horsepower'].fillna(null2, inplace = True)\n",
    "df['weight'].fillna(null3, inplace = True)\n",
    "df['model year'].fillna(null4, inplace = True)\n",
    "df['acceleration'].fillna(null5, inplace = True)\n",
    "df['origin'].fillna(null6, inplace = True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Si revisamos, la variable <i>cylinders</i> presenta un error, y es que en la primera posición poseen caracteres alfabéticos, para ello debemos realizar una transformación adicional</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cylinders'] = df['cylinders'].map(lambda x: x.lstrip('aAbBcCdvpft'))\n",
    "df['cylinders']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Si revisamos el campo de <i> car name </i> encontramos que hay registros numéricos que no son coherentes con el registro, por tanto, al ser la \"llave\", tenemos que eliminar el registro</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['car name'])\n",
    "df = df.drop([18, 24])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['car name'].unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Consultas </h2>\n",
    "<p> Al poseer grandes fuentes de información, es necesario aplicar ciertas funciones sobre nuestras bases de datos que nos permitan visualizar:</p>\n",
    "<ul>\n",
    "    <li> Llave única</li>\n",
    "    <li> Medidas de tendencia de un campo </li>\n",
    "    <li> Total de un campo</li>\n",
    "    <li> Ordenar la base de datos </li>\n",
    "    <li> Eliminar duplicados </li>\n",
    "    <li> Contar valores únicos </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes, \"\\n\\n\\n\")\n",
    "df['cylinders'] = pd.to_numeric(df['cylinders'], errors='coerce')\n",
    "print(df.dtypes, \"\\n\\n\\n\")\n",
    "print('\\n SUMA \\n\\n',df.apply(np.sum),'\\n\\n')\n",
    "print('\\n MEDIA \\n\\n',df.iloc[:,0:8].apply(np.mean),'\\n\\n')\n",
    "print('\\n MEDIANA \\n\\n',df.iloc[:,0:8].apply(np.median),'\\n\\n')\n",
    "print('\\n MODA \\n\\n',df['car name'].mode(),'\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambien es posible ordenar la base de datos, y eliminar aquellos registros que esten duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar la base de datos\n",
    "print('\\n ORDENAR POR AÑO \\n\\n',df.sort_values(by=['model year'], ascending=False),'\\n\\n')\n",
    "print('\\n ORDENAR POR AÑO Y PESO \\n\\n',df.sort_values(by=['model year','weight']),'\\n\\n')\n",
    "print('\\n ¿HAY DUPLICADOS? \\n\\n',df.duplicated(),'\\n\\n')\n",
    "print('\\n ELIMINAR DUPLICADOS \\n\\n',df.drop_duplicates(),'\\n\\n')\n",
    "print('\\n ELIMINAR DUPLICADOS POR COLUMNAS \\n\\n',df.drop_duplicates(['mpg']),'\\n\\n')\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos contar valores únicos, de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n\\n CONTAR VALORES ÚNICOS \\n\\n',df.nunique(),'\\n\\n')\n",
    "print('\\n\\n CONTAR VALORES ÚNICOS \\n\\n',df.count(),'\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Combinar, unir y concatenar </h2>\n",
    "<br></br>\n",
    "<p> En el momento de manejar distintas bases de datos, es importante conocer como podemos obtener información de cada una de ellas</p>\n",
    "<p> En esta sección veremos como combinar, unir y concatenar bases de datos </p>\n",
    "<ul>\n",
    "    <li> Para concatenar un marco de datos, utilizamos la función .concat(), esta función concatena un marco de datos y devuelve un nuevo marco de datos</li>\n",
    "    <li> Para concatenar un marco de datos, utilizamos la función .append() esta función concatena a lo largo del eje = 0, es decir, el índice. </li>\n",
    "    <li> Para juntar bases de datos utilizamos la función .merge()</li>\n",
    " </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Para estos ejercicios tomaremos tres tipos de bases diferentes que nos permitan combinar, unir y juntar. También ubicaremos la llave </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(301, 9)\n",
      "\n",
      "\n",
      " CONTAR VALORES ÚNICOS \n",
      "\n",
      " mpg             109\n",
      "cylinders         5\n",
      "displacement     77\n",
      "horsepower       87\n",
      "weight          275\n",
      "acceleration     90\n",
      "model year       13\n",
      "origin            3\n",
      "car name        301\n",
      "dtype: int64 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " CONTAR VALORES ÚNICOS \n",
      "\n",
      " mpg             301\n",
      "cylinders       301\n",
      "displacement    301\n",
      "horsepower      301\n",
      "weight          301\n",
      "acceleration    301\n",
      "model year      301\n",
      "origin          301\n",
      "car name        301\n",
      "dtype: int64 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Bases de datos\n",
    "df = pd.read_excel('mpg.xlsx','HojaDatos')\n",
    "print(df.shape)\n",
    "# Separar en subconjuntos de índices\n",
    "df1 = df.iloc[0:199]\n",
    "df2 = df.iloc[200:298]\n",
    "# Separar en columnas\n",
    "df3 = df.iloc[0:10,[0,1,2,3,4,8]]\n",
    "df4 = df.iloc[0:13,[5,6,7,8]]\n",
    "print('\\n\\n CONTAR VALORES ÚNICOS \\n\\n',df.nunique(),'\\n\\n')\n",
    "print('\\n\\n CONTAR VALORES ÚNICOS \\n\\n',df.count(),'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 9) \n",
      "\n",
      "\n",
      "            mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
      "train 0    18.0          8         307.0       130.0    3504          12.0   \n",
      "      1    15.0          8         350.0       165.0    3693          11.5   \n",
      "      2    18.0          8         318.0       150.0    3436          11.0   \n",
      "      3    16.0          8         304.0       150.0    3433          12.0   \n",
      "      4    17.0          8         302.0       140.0    3449          10.5   \n",
      "...         ...        ...           ...         ...     ...           ...   \n",
      "test  296  27.0          4         140.0        86.0    2790          15.6   \n",
      "      297  44.0          4          97.0        52.0    2130          24.6   \n",
      "      298  32.0          4         135.0        84.0    2295          11.6   \n",
      "      299  28.0          4         120.0        79.0    2625          18.6   \n",
      "      300  31.0          4         119.0        82.0    2720          19.4   \n",
      "\n",
      "           model year  origin                     car name  \n",
      "train 0            70       1  \"chevrolet chevelle malibu\"  \n",
      "      1            70       1          \"buick skylark 320\"  \n",
      "      2            70       1         \"plymouth satellite\"  \n",
      "      3            70       1              \"amc rebel sst\"  \n",
      "      4            70       1                \"ford torino\"  \n",
      "...               ...     ...                          ...  \n",
      "test  296          82       1            \"ford mustang gl\"  \n",
      "      297          82       2                  \"vw pickup\"  \n",
      "      298          82       1              \"dodge rampage\"  \n",
      "      299          82       1                \"ford ranger\"  \n",
      "      300          82       1                 \"chevy s-10\"  \n",
      "\n",
      "[300 rows x 9 columns] \n",
      "\n",
      "\n",
      "(300, 9)\n"
     ]
    }
   ],
   "source": [
    "# Concatenación\n",
    "df5 = pd.concat([df1,df2]) # , ignore_index=True\n",
    "df6 = pd.concat([df1,df2],keys=['train', 'test'])\n",
    "print(df5.shape,'\\n\\n')\n",
    "print(df6,'\\n\\n')\n",
    "\n",
    "df5 = df1.append(df2)\n",
    "print(df5.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Uniones </h3>\n",
    "<p> Las uniones consisten en combinaciones de dos bases de datos con el uso de una llave, que por buena práctica, en al menos una de las bases debe ser única. </p> \n",
    "<p> Con este tipo de acciones podemos agregar información, buscar información relevante y estructurar los datos </p>\n",
    "<br></br>\n",
    "<img src= 'merge.png',width=400,heigth=1000, alt=\"Flowers in Chania\">\n",
    "<center> <i> Imagen tomada de <a href=\"https://www.geeksforgeeks.org/python-pandas-merging-joining-and-concatenating/\"> geeksforgeeks</a> </i></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union1 = pd.merge(df3, df4, on='car name')\n",
    "union1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union2 = pd.merge(df3, df4, how='left', on=['car name'])\n",
    "union3 = pd.merge(df3, df4, how='right',  on=['car name'])\n",
    "union4 = pd.merge(df3, df4, how='inner',  on=['car name'])\n",
    "union5 = pd.merge(df3, df4, how='outer',  on=['car name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Exportar base </h3>\n",
    "<p>Al trabajar con bases de datos, en muchas ocasiones necesitamos exportar los resultados para utilizarla en otros entornos, por espacio, por eficiencia, o por otros criterios.</p>\n",
    "<p> En este caso exportaremos la base de datos en 3 escenarios: </p>\n",
    "<ul>\n",
    "    <li> .txt </li>\n",
    "    <li> .csv </li>\n",
    "    <li> .xlsx </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"mpg1.xlsx\", \"Sheet1\")\n",
    "df.to_csv(\"mpg1.csv\")\n",
    "df.to_csv(\"mpg1.txt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
