{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center> Ejercicio en Clase 2 </center> </h1>\n",
    "El siguiente ejercicio en clase busca abordar un problema de clasificación con el uso de las distintas técnicas vistas en clase, para ello presentamos a continuación desde la exploración de la información, balanceo de los datos, y las distintas aproximaciones y comparaciones entre los modelos de clasificación.\n",
    "Cada sección posee una serie de ejercicios que usted tendrá que solucionar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolución de un modelo de machine learning\n",
    "* Definición del objetivo\n",
    "* Exploración de los datos\n",
    "* Procesamiento de datos\n",
    "* Estimación de los modelos\n",
    "* Evaluar la capacidad de predicción de los modelos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo\n",
    "Estimar que pasajetos murieron en el hundimiento del Titanic, dado unas caracterísitas demográficas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base de datos\n",
    "La base de datos del Titanic es una muestra de la tripulación que navego en el barco. Se compone de los siguientes campos:\n",
    "* **PassengerId:** Identificador del pasajero\n",
    "* **Survived:** El pasajero sobrevivio o no (0 = No, 1 = Sí)\n",
    "* **Pclass:** La clase del boleto que compró el pasajero (1 = 1er, 2 = 2do, 3 = 3ro)\n",
    "* **Name:** Nombre del pasajero\n",
    "* **Sex:** El sexo del pasajero\n",
    "* **Age:** Edad del pasajero\n",
    "* **SibSp:** La cantidad de hermanos o cónyuges que el pasajero tenía a bordo del Titanic\n",
    "* **Parch:** El número de padres o hijos que el pasajero tenía a bordo del Titanic\n",
    "* **Ticket:** El número de boleto del pasajero\n",
    "* **Fare:** La tarifa que pagó el pasajero\n",
    "* **Cabin:** El número de cabina del pasajero\n",
    "* **Embarked:** El puerto donde se embarcó el pasajero (C = Cherbourg, Q = Queenstown, S = Southampton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "#Visualitation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style('darkgrid')\n",
    "plt.style.use('seaborn-poster')\n",
    "\n",
    "#Warnings\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Data manipulation with scikit learning\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "# Models\n",
    "import statsmodels.api as sm2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Metrics and hyperparameters\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "from sklearn.metrics import confusion_matrix, precision_score, accuracy_score\n",
    "from sklearn.metrics import recall_score, f1_score, roc_auc_score, roc_curve "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv(\"titanic.csv\")\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 0:\n",
    "¿Cuáles variables considera relevantes para realizar la estimación de nuestros modelos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escriba aquí su respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento de datos\n",
    "En el curso hemos visto distintas técnicas de procesamiento de datos, en este caso nos encargaremos de los NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, ```Cabin``` tiene una alta cantidad de ```NAs``` ante ello, podemos eliminar esta variable del ejercicio, pues dada la descripción es posible que no aporte nada a nuestra estimación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1\n",
    "¿Cuál es el porcentaje de valores ausentes para las variables ```Cabin``` y ```Age```?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escriba aquí su respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = titanic.drop(columns='Cabin')\n",
    "titanic = titanic.dropna()\n",
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploración de datos\n",
    "Si bien no hemos visto visualización en el curso, hagamos una exploración sencilla de la información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Survived'].hist(bins=3);\n",
    "plt.xticks([0,1]);\n",
    "plt.title(\"Survived Distribution\",fontweight=\"bold\" )\n",
    "plt.xlabel(\"Frequency\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2\n",
    "¿Qué información obtiene del gráfico de histogramas de ```Survived```? ¿Cuántas personas que sobrevivieron y cuántas no? ¿Considera que tenemos una base de datos desbalanceada?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escriba su respuesta aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algunas modificaciones\n",
    "Del **Ejercicio 0** es posible encontrar que hay variables que no serán relevantes a la hora de realizar la estimación, pero, de ellas podemos obtener cierta información \"escondida\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo de las variables ```SibSp``` y ```Parch``` podemos encontrar si el pasajero viaja solo o no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['FamilySize'] = titanic['SibSp'] + titanic['Parch'] + 1\n",
    "titanic['IsAlone'] = 0\n",
    "titanic.loc[titanic['FamilySize'] == 1, 'IsAlone'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien ```Age``` es flotante, es una variable discreta que podemos convertir a nivel categórico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Age'] = titanic['Age'].astype(int)\n",
    "titanic['CategoricalAge'] = pd.cut(titanic['Age'], 5)\n",
    "list(titanic['CategoricalAge'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que ```Age```, ```Fare``` también es flotante, la cuál podemos convertir a nivel categórico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Fare'] = titanic['Fare'].astype(int)\n",
    "titanic['CategoricalFare'] = pd.cut(titanic['Fare'], 4)\n",
    "list(titanic['CategoricalFare'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De los nombres de los pasajeros, podemos tomar su titulo, por ejemplo si es ```Mister``` o ```Miss```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "titanic['Title'] = titanic['Name'].apply(get_title)\n",
    "titanic['Title'] = titanic['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', \n",
    "                                             'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "titanic['Title'] = titanic['Title'].replace('Mlle', 'Miss')\n",
    "titanic['Title'] = titanic['Title'].replace('Ms', 'Miss')\n",
    "titanic['Title'] = titanic['Title'].replace('Mme', 'Mrs')\n",
    "print(titanic['Title'].value_counts())\n",
    "\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "titanic['Title'] = titanic['Title'].map(title_mapping)\n",
    "titanic['Title'] = titanic['Title'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunas modificaciones adicionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Sex'] = titanic['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "\n",
    "# Mapping Embarked\n",
    "titanic['Embarked'] = titanic['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "\n",
    "# Mapping Fare\n",
    "titanic.loc[ titanic['Fare'] <= 128.0, 'Fare'] \t\t\t\t\t\t        = 0\n",
    "titanic.loc[(titanic['Fare'] > 128.0) & (titanic['Fare'] <= 256.0), 'Fare'] = 1\n",
    "titanic.loc[(titanic['Fare'] > 256.0) & (titanic['Fare'] <= 384.0), 'Fare']   = 2\n",
    "titanic.loc[ titanic['Fare'] > 384.0, 'Fare'] \t\t\t\t\t\t\t        = 3\n",
    "titanic['Fare'] = titanic['Fare'].astype(int)\n",
    "\n",
    "# Mapping Age\n",
    "titanic.loc[ titanic['Age'] <= 18, 'Age'] \t\t\t\t\t       = 0\n",
    "titanic.loc[(titanic['Age'] > 18) & (titanic['Age'] <= 32), 'Age'] = 1\n",
    "titanic.loc[(titanic['Age'] > 32) & (titanic['Age'] <= 48), 'Age'] = 2\n",
    "titanic.loc[(titanic['Age'] > 48) & (titanic['Age'] <= 64), 'Age'] = 3\n",
    "titanic.loc[ titanic['Age'] > 64, 'Age']                           = 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del anterior ejercicio se encontro que cierta información, tal vez no sea relevante de manera directa, pero de ella podemos tomar ciertos datos que nos permitan obtener otro conjunto de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = titanic.drop(columns=['PassengerId', 'Name', 'Ticket', 'SibSp','Parch', 'FamilySize','CategoricalAge',\n",
    "                                'CategoricalFare','FamilySize'])\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribución de las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['Pclass', 'Sex',\"Age\",\"Fare\",'Embarked',\"IsAlone\",'Title']\n",
    "\n",
    "plt.figure(figsize=(30,50))    \n",
    "for i, features in enumerate(variables):\n",
    "    plt.subplot(4,2,i+1)\n",
    "    titanic[features][titanic['Survived'] == 0].hist()\n",
    "    titanic[features][titanic['Survived'] == 1].hist()\n",
    "    title = str(variables[i])\n",
    "    plt.title(title, fontsize=18, verticalalignment='bottom',fontweight=\"bold\");\n",
    "    plt.xticks(list(titanic[features].unique()));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "sns.heatmap(titanic.corr(), cmap=\"RdYlBu\", annot=True, square=True,vmin=-0.8, vmax=0.8, fmt=\"+.1f\")\n",
    "plt.title(\"Correlations between predictors\")\n",
    "titanic.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estandarización de la información\n",
    "\n",
    "Como vimos en la sesión pasada, en varios casos es importante realizar la estandarización\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler()\n",
    "\n",
    "titanic['Pclass'] = std_scaler.fit_transform(titanic['Pclass'].values.reshape(-1,1))\n",
    "titanic['Sex'] = std_scaler.fit_transform(titanic['Sex'].values.reshape(-1,1))\n",
    "titanic['Age'] = std_scaler.fit_transform(titanic['Age'].values.reshape(-1,1))\n",
    "titanic['Fare'] = std_scaler.fit_transform(titanic['Fare'].values.reshape(-1,1))\n",
    "titanic['Embarked'] = std_scaler.fit_transform(titanic['Embarked'].values.reshape(-1,1))\n",
    "titanic['IsAlone'] = std_scaler.fit_transform(titanic['IsAlone'].values.reshape(-1,1))\n",
    "titanic['Title'] = std_scaler.fit_transform(titanic['Title'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelación\n",
    "Ahora para poder predecir si un pasajero sobrevive o no, tenemos en cuenta varios elementos. Primero que nuestra variable target es categorica/binaria, segundo, que existe una variable categórica, por lo que, de las anteriores sesiones observamos distintas técnicas para realizar modelaciones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos de entrenamiento y de validación\n",
    "De nuestros ejercicios, siempre hemos separado la información, entre entrenamiento y validación/testeo. En este caso, dividiremos nuestra información en 70% de entrenamiento y 30% de testeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = titanic.Survived\n",
    "X = titanic.drop('Survived', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Logística\n",
    "Una regresión logistica se basa en la idea de la regresión lineal, salvo que ajusta el resultado en un número entre 0 y 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression()\n",
    "logit_model = logit.fit(X_train,y_train)\n",
    "logit_pred = logit_model.predict(X_test)\n",
    "logit_roc_auc = roc_auc_score(y_test, logit_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naïve Bayes\n",
    "Este algoritmo simple esta basado en el Teorema de Bayes. Este asume que el efecto de una característica particular en una clase es independiente de otras características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_train_test(params):\n",
    "    clf = BernoulliNB(**params)\n",
    "    return cross_val_score(clf, X_train, y_train).mean()\n",
    "space4knn = {\n",
    "    'alpha': hp.uniform('alpha', 0.0, 2.0)\n",
    "}\n",
    "\n",
    "def f(params):\n",
    "    acc = hyperopt_train_test(params)\n",
    "    return {'loss': -acc, 'status': STATUS_OK}\n",
    "trials = Trials()\n",
    "best = fmin(f, space4knn, algo=tpe.suggest, max_evals=100, trials=trials)\n",
    "print('best:')\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaiveBayes = BernoulliNB(alpha=1.831435386045045)\n",
    "NB_model = NaiveBayes.fit(X_train,y_train)\n",
    "NB_pred = NB_model.predict(X_test)\n",
    "NB_roc_auc = roc_auc_score(y_test, NB_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbor\n",
    "Este es un algoritmo simple con el que se pueden abordar problemas de reconocimiento de patrones, minería de datos/texto, detección de intrusos, entre otros, en el que el conjunto de datos puede ser no paramétrico (No hay suposición explicita sobre la forma funcional de los datos) y este algoritmos esta basado en instancias, es decir, el algoritmo no aprende directamente del modelo, sino de las instancias de información, que son utilizadas como \"conocimiento\" para poder clasificar los datos nuveos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_train_test(params):\n",
    "    clf = KNeighborsClassifier(**params)\n",
    "    return cross_val_score(clf, X_train, y_train).mean()\n",
    "space4knn = {\n",
    "    'n_neighbors': hp.choice('n_neighbors', range(2,10))\n",
    "}\n",
    "def f(params):\n",
    "    acc = hyperopt_train_test(params)\n",
    "    return {'loss': -acc, 'status': STATUS_OK}\n",
    "trials = Trials()\n",
    "best = fmin(f, space4knn, algo=tpe.suggest, max_evals=100, trials=trials)\n",
    "print('best:')\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier(n_neighbors=5)\n",
    "KNN_model = KNN.fit(X_train,y_train)\n",
    "KNN_pred = KNN_model.predict(X_test)\n",
    "KNN_roc_auc = roc_auc_score(y_test, KNN_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "Es una técnica de machine learning no supervisado en la cual, por medio de una representación esquemática de las variables facilita la toma de mejores decisiones puesto qeu me permite realizar predicciones sobre algún fenómeno. Estos son similares a diagramas de flujo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_train_test(params):\n",
    "    clf = DecisionTreeClassifier(**params)\n",
    "    return cross_val_score(clf, X_train, y_train).mean()\n",
    "space4dt = {\n",
    "    'max_depth': hp.choice('max_depth', range(1,20)),\n",
    "    'max_features': hp.choice('max_features', range(1,5)),\n",
    "    'criterion': hp.choice('criterion', [\"gini\", \"entropy\"])\n",
    "}\n",
    "def f(params):\n",
    "    acc = hyperopt_train_test(params)\n",
    "    return {'loss': -acc, 'status': STATUS_OK}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(f, space4dt, algo=tpe.suggest, max_evals=100, trials=trials)\n",
    "print('best:')\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier(criterion = \"gini\", max_depth = 15, max_features = 3)\n",
    "DT.fit(X_train,y_train)\n",
    "DT_pred = DT.predict(X_test)\n",
    "DT_roc_auc = roc_auc_score(y_test, DT_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "Son arboles de decisión construidos en paralelo, los cuales basan su estimación en una submuestra aleatoria del conjunto de información, y al igual que el arbol de decisión este método esta delimitado por los hiperparametros de profundidad, caracteristicas por nodo, estimadores máximos utilizados por cada arbol y el criterio de selección"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_train_test(params):\n",
    "    clf = RandomForestClassifier(**params)\n",
    "    return cross_val_score(clf, X_train, y_train).mean()\n",
    "space4rf = {\n",
    "    'max_depth': hp.choice('max_depth', range(1,20)),\n",
    "    'max_features': hp.choice('max_features', range(1,5)),\n",
    "    'n_estimators': hp.choice('n_estimators', range(1,20)),\n",
    "    'criterion': hp.choice('criterion', [\"gini\", \"entropy\"])\n",
    "}\n",
    "best = 0\n",
    "def f(params):\n",
    "    acc = hyperopt_train_test(params)\n",
    "    return {'loss': -acc, 'status': STATUS_OK}\n",
    "trials = Trials()\n",
    "best = fmin(f, space4rf, algo=tpe.suggest, max_evals=100, trials=trials)\n",
    "print('best:')\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(criterion=\"entropy\", max_depth=2, \n",
    "                            n_estimators=15)\n",
    "RF.fit(X_train,y_train)\n",
    "RF_pred = RF.predict(X_test)\n",
    "RF_roc_auc = roc_auc_score(y_test, RF_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting\n",
    "Es una técnica secuencial para la construcción de arboles de decisión, en la que en cada rama buscara el subarbol que mayor ```exactitud```arroje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_train_test(params):\n",
    "    clf = GradientBoostingClassifier(**params)\n",
    "    return cross_val_score(clf, X_train, y_train).mean()\n",
    "space4rf = {\n",
    "    'max_depth': hp.choice('max_depth', range(1,20)),\n",
    "    'max_features': hp.choice('max_features', range(1,5)),\n",
    "    'n_estimators': hp.choice('n_estimators', range(1,20)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(1))}\n",
    "best = 0\n",
    "def f(params):\n",
    "    acc = hyperopt_train_test(params)\n",
    "    return {'loss': -acc, 'status': STATUS_OK}\n",
    "trials = Trials()\n",
    "best = fmin(f, space4rf, algo=tpe.suggest, max_evals=100, trials=trials)\n",
    "print('best:')\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB = GradientBoostingClassifier(learning_rate= 0.9938635068502856,max_depth=16,max_features=1,n_estimators=13)\n",
    "GB.fit(X_train, y_train)\n",
    "GB_pred = GB.predict(X_test)\n",
    "GB_roc_auc = roc_auc_score(y_test, GB_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación entre los distintos modelos\n",
    "En este caso seleccionamos el criterio de la curva de ROC para seleccionar cual es el mejor modelo.\n",
    "El área bajo la curva (AUC) y la curva ROC son métricas de evaluación para verificar el rendimiento de un modelo de clasificación\n",
    "La curva ROC nos dice que tan bueno puede distiguir un modelo entre 2 clases distintas Mientras que AUC, mide la probabilidad de que el modelo clasifique un ejemplo positivo aleatorio más alto que un ejemplo negativo aleatorio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Regresión Logit: ',logit_roc_auc)\n",
    "print('Naïve Bayes: ',NB_roc_auc)\n",
    "# print('K Near Neighbor: ',KNN_roc_auc)\n",
    "print('Árbol de decisión: ',DT_roc_auc)\n",
    "print('Random Forest: ',RF_roc_auc)\n",
    "print('Gradient Boosting: ',GB_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_fpr, logit_tpr, thresholds = roc_curve(y_test, logit.predict_log_proba(X_test)[:,1])\n",
    "NB_fpr, NB_tpr, thresholds = roc_curve(y_test, NB_model.predict_proba(X_test)[:, 1])\n",
    "KNN_fpr, KNN_tpr, thresholds = roc_curve(y_test, KNN_model.predict_proba(X_test)[:, 1])\n",
    "DT_fpr, DT_tpr, thresholds = roc_curve(y_test, DT.predict_proba(X_test)[:, 1])\n",
    "RF_fpr, RF_tpr, thresholds = roc_curve(y_test, RF.predict_proba(X_test)[:, 1])\n",
    "GB_fpr, GB_tpr, thresholds = roc_curve(y_test, GB.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(logit_fpr, logit_tpr, label='Regresión Logística')\n",
    "plt.plot(NB_fpr, NB_tpr, label='NB')\n",
    "plt.plot(KNN_fpr, KNN_tpr, label='KNN')\n",
    "plt.plot(DT_fpr, DT_tpr, label='DT')\n",
    "plt.plot(RF_fpr, RF_tpr, label='RF')\n",
    "plt.plot(GB_fpr, GB_tpr, label='GB')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlabel('Tasa de Falsos Positivos')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "plt.title('Característica de funcionamiento del receptor (Curva ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3:\n",
    "1. Evalue las distintas métricas en cada modelo\n",
    "2. Realice el mismo ejercicio con al menos alguna de las técnicas de balanceo de datos ¿Cuál es el mejor modelo para predecir si un pasajero sobrevive o no?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escriba aquí su respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
