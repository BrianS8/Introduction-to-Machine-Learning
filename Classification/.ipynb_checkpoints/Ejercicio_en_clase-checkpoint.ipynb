{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center> Ejercicio en clase </center> </h1>\n",
    "<p> El siguiente ejercicio en clase busca abordar un problema de clasificación con el uso de las distintas técnicas vistas en clase, para ello presentamos a continuación desde la exploración de la información, balanceo de los datos, hasta las distintas aproximaciones y comparaciones entre los modelos. </p>\n",
    "<p> Cada sección posee una serie de ejercicios que usted tendrá que solucionar, por el momento no se preocupe, que lo realizaremos como equipo </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio\n",
    "En este ejercicio buscamos detectar si una operación es un fraude o no, para ello utilizaremos distintas técnicas que nos permitan aproximarnos a la respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base de datos\n",
    "En este ejercicio seleccionaremos una base de datos denominada como ```credit```, la cual contienen las transacciones realizadas en dos días con tarjetas de crédito en septiembre de 2013 en Europa. En estos datos se identifican 492 fraudes de 284,807 transacciones. El conjunto de datos está altamente desequilibrado, pues la clase positiva (fraudes) representa el 0.172% de todas las transacciones.\n",
    "\n",
    "Por temas de confidencialidad esta base de datos contiene información anonimizada con PCA,  (V1,...,V28), exceptuando las características  ```Tiempo``` y ```Cantidad```. La variable ```Tiempo``` contiene los segundos transcurridos entre cada transacción, mientras que la variable ```Cantidad``` es la Cantidad de la transacción, mientras que la variable ```Clase``` es la variable de respuesta y toma el valor 1 en caso de fraude y 0 en caso contrario.\n",
    "\n",
    "Esta base de datos la puede encontrar en el siguiente [link](https://www.kaggle.com/mlg-ulb/creditcardfraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classic and data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Data manipulation with scikit learning\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "# Models\n",
    "import statsmodels.api as sm2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Metrics and hyperparameters\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "from sklearn.metrics import confusion_matrix, precision_score, accuracy_score\n",
    "from sklearn.metrics import recall_score, f1_score, roc_auc_score, roc_curve "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploración de la base de datos\n",
    "Comencemos con una exploración básica de la información de créditos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('credit.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.759072e-12</td>\n",
       "      <td>-8.251146e-13</td>\n",
       "      <td>-9.655448e-13</td>\n",
       "      <td>8.321385e-13</td>\n",
       "      <td>1.649983e-13</td>\n",
       "      <td>4.248434e-13</td>\n",
       "      <td>-3.054696e-13</td>\n",
       "      <td>8.777981e-14</td>\n",
       "      <td>-1.179757e-12</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.405785e-13</td>\n",
       "      <td>-5.723165e-13</td>\n",
       "      <td>-9.725860e-13</td>\n",
       "      <td>1.464148e-12</td>\n",
       "      <td>-6.987110e-13</td>\n",
       "      <td>-5.617884e-13</td>\n",
       "      <td>3.332082e-12</td>\n",
       "      <td>-3.518875e-12</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.759072e-12 -8.251146e-13 -9.655448e-13  8.321385e-13   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   1.649983e-13  4.248434e-13 -3.054696e-13  8.777981e-14 -1.179757e-12   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ... -3.405785e-13 -5.723165e-13 -9.725860e-13  1.464148e-12   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean  -6.987110e-13 -5.617884e-13  3.332082e-12 -3.518875e-12      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.Class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio\n",
    "Realice una tabla en la que calcule el porcentaje de clases 0 y 1 que tenemos en la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escriba aquí su código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Distribución de Fraude')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = [\"#0101DF\", \"#DF0101\"]\n",
    "sns.countplot('Class', data=dataset, palette=colors)\n",
    "plt.title('Distribución de Fraude', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es claro que nuestra base se encuentra desbalanceada, es decir, tenemos muy poca información para identificar patrones de fraude en las transacciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escalar / Estandarizar\n",
    "\n",
    "Para poder manejar las distintas variables en una misma escala un camino consiste en la estandarización de la información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.783274</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.269825</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.983721</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.418291</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.670579</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   scaled_amount        V1        V2        V3        V4        V5        V6  \\\n",
       "0       1.783274 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1      -0.269825  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2       4.983721 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3       1.418291 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4       0.670579 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "\n",
       "         V7        V8        V9  ...       V20       V21       V22       V23  \\\n",
       "0  0.239599  0.098698  0.363787  ...  0.251412 -0.018307  0.277838 -0.110474   \n",
       "1 -0.078803  0.085102 -0.255425  ... -0.069083 -0.225775 -0.638672  0.101288   \n",
       "2  0.791461  0.247676 -1.514654  ...  0.524980  0.247998  0.771679  0.909412   \n",
       "3  0.237609  0.377436 -1.387024  ... -0.208038 -0.108300  0.005274 -0.190321   \n",
       "4  0.592941 -0.270533  0.817739  ...  0.408542 -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Class  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053      0  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724      0  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458      0  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_scaler = StandardScaler()\n",
    "rob_scaler = RobustScaler()\n",
    "\n",
    "dataset['scaled_amount'] = std_scaler.fit_transform(dataset['Amount'].values.reshape(-1,1))\n",
    "dataset['scaled_time'] = std_scaler.fit_transform(dataset['Time'].values.reshape(-1,1))\n",
    "\n",
    "dataset.drop(['Time','Amount'], axis=1, inplace=True)\n",
    "scaled_amount = dataset['scaled_amount']\n",
    "scaled_time = dataset['scaled_time']\n",
    "\n",
    "dataset.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)\n",
    "dataset.insert(0, 'scaled_amount', scaled_amount)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanceo de la base de datos\n",
    "Para este caso, existen múltiples soluciones, entre ellas:\n",
    "1. No tener en cuenta las métricas de precisión y puntajes F1 a la hora de validar los modelos\n",
    "2. Trabajar con algoritmos adecuados - Random Forest\n",
    "3. Trabajar con técnicas de remuestreo que aumente o disminuyan la información\n",
    "4. Generación de muestras sintéticas\n",
    "\n",
    "En este ejercicio se mostraran las distintas técnicas, pero solo se trabajara con una de ellas, como ejercicio usted deberá seleccionar la muestra que mejor se adecue a lo que está buscando\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reducción de la muestra de la clase dominante con remuestreo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    492\n",
       "0    492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataset.sample(frac=1)\n",
    "\n",
    "df_fraude = df.loc[df['Class'] == 1]\n",
    "df_n_fraude = df.loc[df['Class'] == 0][:492]\n",
    "\n",
    "df_tamaño = pd.concat([df_fraude, df_n_fraude])\n",
    "df = df_tamaño.sample(frac=1, random_state=42)\n",
    "\n",
    "df.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    492\n",
       "0    492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fraude = dataset.loc[dataset['Class'] == 1]\n",
    "df_n_fraude = dataset.loc[dataset['Class'] == 0]\n",
    "\n",
    "df_n_fraude = resample(df_n_fraude,\n",
    "                       replace = False,\n",
    "                       n_samples = len(df_fraude),\n",
    "                       random_state = 27)\n",
    "\n",
    "df2 = pd.concat([df_n_fraude, df_fraude])\n",
    "\n",
    "df2.Class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aumento de la muestra de la clase no dominante con remuestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    213245\n",
       "0    213245\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dataset.Class\n",
    "X = dataset.drop('Class', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)\n",
    "X = pd.concat([X_train, y_train], axis=1)\n",
    "df_n_fraude = X[X.Class==0]\n",
    "df_fraude = X[X.Class==1]\n",
    "\n",
    "df3 = resample(df_fraude,\n",
    "               replace=True,\n",
    "               n_samples=len(df_n_fraude),\n",
    "               random_state=27)\n",
    "\n",
    "df3 = pd.concat([df_n_fraude, df3])\n",
    "\n",
    "df3.Class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balanceo con muestra sintentica\n",
    "Esta técnica busca un submuestre de la información con los vecinos más cercanos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0, 213245],\n",
       "       [     1, 213245]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dataset.Class\n",
    "X = dataset.drop('Class', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)\n",
    "sm = SMOTE(random_state=27, ratio=1.0)\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train)\n",
    "np.array(np.unique(y_train, return_counts=True)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento con distintos modelos\n",
    "\n",
    "Al tener balanceada nuestra información balanceada, procederemos a evaluar los distintos modelos y seleccionar aquel que mejor resultado nos arroje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimación (Tuning) de los Hiperparametros\n",
    "Los hiperparametros son instancias que permite la parametrización del modelo a una función objetivo, por ejemplo la cantidad de ramificaciones que tendrá un modelo, el número mínimo de nodos, entre otros casos\n",
    "\n",
    "Existen múltiples caminos para hallar los hiperparametros más adecuados a la hora de realizar modelación, entre ellos tenemos:\n",
    "1. Busqueda de cuadricula: Probar todas las combinaciones posibles\n",
    "2. Busqueda aleatoria: Probar combinaciones aleatorias\n",
    "3. Optimización Bayesiana:  Trata de encontrar el valor que minimiza una función objetivo mediante la construcción de un modelo de probabilidad basado en resultados de evaluaciones anteriores de la métrica objetiva\n",
    "\n",
    "Todo lo anterior es basado en la metrica de ```exactitud``` la cual busca encontrar cual fue el porcenta de datos predichos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de regresión logística\n",
    "Una regresión logistica se basa en la idea de la regresión lineal, salvo que ajusta el resultado en un número entre 0 y 1. Así entre las funciones más utilizadas se tiene la función sigmoide, la cual establece:\n",
    "\n",
    "$$\\sigma \\left ( x \\right ) = {\\displaystyle \\frac{1}{1+e^{-x}}}$$\n",
    "\n",
    "Esrta también se conoce como la función de distribución acumulada de una regresión logistica. Si $x = \\beta_{0}+\\beta_{1}x_{1}$, entonces: \n",
    "\n",
    "$$ \\sigma \\left ( x \\right ) = {\\displaystyle \\frac{1}{1+e^{-\\beta_{0}-\\beta_{1}x_{1}}}}$$\n",
    "\n",
    "Entonces, si tomamos la pendiente de la curva, tenemos\n",
    "\n",
    "$${\\displaystyle \\frac{\\partial p_{i}}{\\partial x_{i}}=\\beta p_{i}\\left(1-p_{i}\\right)}$$\n",
    "\n",
    "Esto se conoce como el efecto marginal de $x$ en un evento de probabilidad\n",
    "Por ejemplo, cuando $\\beta = 1$ y $p = 0.5$, un aumento de $1$ unidad en $x$ produce un aumento de $0.25$ en la probabilidad de ocurrencia de un evento. Cuando $\\beta$ es más grande, la pendiente de la curva en forma de S y con $p = 0.5$ es más pronunciada. Cuando $\\beta$ es negativo, la curva se voltea horizontalmente para que $p$ esté cerca de $1$ cuando $x$ es pequeño y cerca de 0 cuando $x$ es grande. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "logit = LogisticRegression(solver='lbfgs')\n",
    "logit_model = logit.fit(X_train,y_train)\n",
    "logit_pred = logit_model.predict(X_test)\n",
    "logit_roc_auc = roc_auc_score(y_test, logit_pred)\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naïve Bayes\n",
    "\n",
    "Este algoritmo simple esta basado en el Teorema de Bayes. Este asume que el efecto de una característica particular en una clase es independiente de otras características\n",
    "$$ P(h|D) = \\frac{P(D|h)P(D)}{P(h)}$$\n",
    "\n",
    "Supone independencia entre los predictores, conocido como interdependencia condicional de clase, esto lo hace ingenuo\n",
    "\n",
    "$P(h):$ probabilidad de que la hipótesis h sea cierta (independientemente de los datos). Esto se conoce como la probabilidad previa de h.\n",
    "<br/>\n",
    "$P(D):$ probabilidad de los datos (independientemente de la hipótesis). Esto se conoce como probabilidad previa.\n",
    "\n",
    "$P(D|h):$ probabilidad de los datos D, dado h.\n",
    "<br/>\n",
    "$P(h|D):$ probabilidad de que la hipótesis h dado un conjunto de datos D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:08<00:00,  1.23it/s, best loss: -0.9125067415744194]\n",
      "best:\n",
      "{'alpha': 0.13054847911498313}\n"
     ]
    }
   ],
   "source": [
    "def hyperopt_train_test(params):\n",
    "    clf = BernoulliNB(**params)\n",
    "    return cross_val_score(clf, X_train, y_train).mean()\n",
    "space4knn = {\n",
    "    'alpha': hp.uniform('alpha', 0.0, 2.0)\n",
    "}\n",
    "\n",
    "def f(params):\n",
    "    acc = hyperopt_train_test(params)\n",
    "    return {'loss': -acc, 'status': STATUS_OK}\n",
    "trials = Trials()\n",
    "best = fmin(f, space4knn, algo=tpe.suggest, max_evals=10, trials=trials)\n",
    "print('best:')\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaiveBayes = BernoulliNB(alpha=0.09827861224760026)\n",
    "NB_model = NaiveBayes.fit(X_train,y_train)\n",
    "NB_pred = NB_model.predict(X_test)\n",
    "NB_roc_auc = roc_auc_score(y_test, NB_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbor\n",
    "\n",
    "<p>Este es un algoritmo simple con el que se pueden abordar problemas de reconocimiento de patrones, minería de datos/texto, detección de intrusos, entre otros, en el que el conjunto de datos puede ser no paramétrico (No hay suposición explicita sobre la forma funcional de los datos) y este algoritmos esta basado en instancias, es decir, el algoritmo no aprende directamente del modelo, sino de las instancias de información, que son utilizadas como \"conocimiento\" para poder clasificar los datos nuveos.\n",
    "\n",
    "El algoritmo funciona de la siguiente manera:\n",
    "1. Se selecciona el punto en el que se encuentra el registro al cual se le va a realizar la predicción\n",
    "2. Dado un hiperparametro ```k```, que se entiende el número de vecinos por cada grupo,  se seleccionan los vecinos más cercanos a este punto usando las siguientes medidas:\n",
    "    1. Distancia Euclidiana\n",
    "    2. Distancia Manhattan\n",
    "    3. Distancia Minkowski\n",
    "3. Por medio de \"votación\", se selecciona la clase de este nuevo elemento\n",
    "</p>\n",
    "\n",
    "### K\n",
    "<p>No existe un número para todo tipo de datos, por lo que depende del criterio del modelador para su selección. Pero esto conlleva unos problemas, si K es muy pequeño entonces tendremos alta varianza pero poco sesgo, mientras que si K es muy alto no tendremos alta varianza pero si un alto sesgo.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [2:13:50<14:09, 849.67s/it, best loss: -0.998750263308236]    "
     ]
    }
   ],
   "source": [
    "def hyperopt_train_test(params):\n",
    "    clf = KNeighborsClassifier(**params)\n",
    "    return cross_val_score(clf, X_train, y_train).mean()\n",
    "space4knn = {\n",
    "    'n_neighbors': hp.choice('n_neighbors', range(2,10))\n",
    "}\n",
    "def f(params):\n",
    "    acc = hyperopt_train_test(params)\n",
    "    return {'loss': -acc, 'status': STATUS_OK}\n",
    "trials = Trials()\n",
    "best = fmin(f, space4knn, algo=tpe.suggest, max_evals=10, trials=trials)\n",
    "print('best:')\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier(n_neighbors=2)\n",
    "KNN_model = KNN.fit(X_train,y_train)\n",
    "KNN_pred = KNN_model.predict(X_test)\n",
    "KNN_roc_auc = roc_auc_score(y_test, KNN_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "Es una técnica de machine learning no supervisado en la cual, por medio de una representación esquemática de las variables facilita la toma de mejores decisiones puesto qeu me permite realizar predicciones sobre algún fenómeno. Estos son similares a diagramas de flujo.\n",
    "\n",
    "Para evitar problemas de sesgo y sobreestimación, los árboles de decisión tienen un límite de crecimiento, los cuales estan dados por una penalización dados por la profundidad del árbol, caracteristicas por nodo y el criterio de selección"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "def hyperopt_train_test(params):\n",
    "    clf = DecisionTreeClassifier(**params)\n",
    "    return cross_val_score(clf, X_train, y_train).mean()\n",
    "space4dt = {\n",
    "    'max_depth': hp.choice('max_depth', range(1,20)),\n",
    "    'max_features': hp.choice('max_features', range(1,5)),\n",
    "    'criterion': hp.choice('criterion', [\"gini\", \"entropy\"])\n",
    "}\n",
    "def f(params):\n",
    "    acc = hyperopt_train_test(params)\n",
    "    return {'loss': -acc, 'status': STATUS_OK}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(f, space4dt, algo=tpe.suggest, max_evals=10, trials=trials)\n",
    "print('best:')\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier(criterion = \"gini\", max_depth = 16, max_features = 3)\n",
    "DT.fit(X_train,y_train)\n",
    "DT_pred = DT.predict(X_test)\n",
    "DT_roc_auc = roc_auc_score(y_test, DT_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "Son arboles de decisión construidos en paralelo, los cuales basan su estimación en una submuestra aleatoria del conjunto de información, y al igual que el arbol de decisión este método esta delimitado por los hiperparametros de profundidad, caracteristicas por nodo, estimadores máximos utilizados por cada arbol y el criterio de selección"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_train_test(params):\n",
    "    clf = RandomForestClassifier(**params)\n",
    "    return cross_val_score(clf, X_train, y_train).mean()\n",
    "space4rf = {\n",
    "    'max_depth': hp.choice('max_depth', range(1,20)),\n",
    "    'max_features': hp.choice('max_features', range(1,5)),\n",
    "    'n_estimators': hp.choice('n_estimators', range(1,20)),\n",
    "    'criterion': hp.choice('criterion', [\"gini\", \"entropy\"])\n",
    "}\n",
    "best = 0\n",
    "def f(params):\n",
    "    acc = hyperopt_train_test(params)\n",
    "    return {'loss': -acc, 'status': STATUS_OK}\n",
    "trials = Trials()\n",
    "best = fmin(f, space4rf, algo=tpe.suggest, max_evals=10, trials=trials)\n",
    "print('best:')\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(criterion=\"gini\", max_depth=16, max_features=2, \n",
    "                            n_estimators=12)\n",
    "RF.fit(X_train,y_train)\n",
    "RF_pred = RF.predict(X_test)\n",
    "RF_roc_auc = roc_auc_score(y_test, RF_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting\n",
    "Es una técnica secuencial para la construcción de arboles de decisión, en la que en cada rama buscara el subarbol que mayor ```exactitud```arroje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_train_test(params):\n",
    "    clf = GradientBoostingClassifier(**params)\n",
    "    return cross_val_score(clf, X_train, y_train).mean()\n",
    "space4rf = {\n",
    "    'max_depth': hp.choice('max_depth', range(1,20)),\n",
    "    'max_features': hp.choice('max_features', range(1,5)),\n",
    "    'n_estimators': hp.choice('n_estimators', range(1,20)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(1))}\n",
    "best = 0\n",
    "def f(params):\n",
    "    acc = hyperopt_train_test(params)\n",
    "    return {'loss': -acc, 'status': STATUS_OK}\n",
    "trials = Trials()\n",
    "best = fmin(f, space4rf, algo=tpe.suggest, max_evals=3, trials=trials)\n",
    "print('best:')\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB = GradientBoostingClassifier(learning_rate= 0.18726176049598348,max_depth=17,max_features=1,n_estimators=17)\n",
    "GB.fit(X_train, y_train)\n",
    "GB_pred = GB.predict(X_test)\n",
    "GB_roc_auc = roc_auc_score(y_test, GB_pred)\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación entre los distintos modelos\n",
    "En este caso seleccionamos el criterio de la curva de ROC para seleccionar cual es el mejor modelo.\n",
    "\n",
    "El área bajo la curva (AUC) y la curva ROC son métricas de evaluación para verificar el rendimiento de un modelo de clasificación\n",
    "\n",
    "La curva ROC nos dice que tan bueno puede distiguir un modelo entre 2 clases distintas\n",
    "Mientras que AUC, mide la probabilidad de que el modelo clasifique un ejemplo positivo aleatorio más alto que un ejemplo negativo aleatorio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Regresión Logit: ',logit_roc_auc)\n",
    "print('Naïve Bayes: ',NB_roc_auc)\n",
    "print('K Near Neighbor: ',KNN_roc_auc)\n",
    "print('Árbol de decisión: ',DT_roc_auc)\n",
    "print('Random Forest: ',RF_roc_auc)\n",
    "print('Gradient Boosting: ',GB_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_fpr, logit_tpr, thresholds = roc_curve(y_test, logit.predict_log_proba(X_test)[:,1])\n",
    "NB_fpr, NB_tpr, thresholds = roc_curve(y_test, NB_model.predict_proba(X_test)[:, 1])\n",
    "KNN_fpr, KNN_tpr, thresholds = roc_curve(y_test, KNN_model.predict_proba(X_test)[:, 1])\n",
    "DT_fpr, DT_tpr, thresholds = roc_curve(y_test, DT.predict_proba(X_test)[:, 1])\n",
    "RF_fpr, RF_tpr, thresholds = roc_curve(y_test, RF.predict_proba(X_test)[:, 1])\n",
    "GB_fpr, GB_tpr, thresholds = roc_curve(y_test, GB.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(logit_fpr, logit_tpr, label='Regresión Logística')\n",
    "plt.plot(NB_fpr, NB_tpr, label='NB')\n",
    "plt.plot(KNN_fpr, KNN_tpr, label='KNN')\n",
    "plt.plot(DT_fpr, DT_tpr, label='DT')\n",
    "plt.plot(RF_fpr, RF_tpr, label='RF')\n",
    "plt.plot(GB_fpr, GB_tpr, label='GB')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlabel('Tasa de Falsos Positivos')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "plt.title('Característica de funcionamiento del receptor (Curva ROC)')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio\n",
    "\n",
    "Con la base de emails, verifique que se encuentra balanceada, sino balancee la base con cualquier técnica y muestre cuál es la mejor técnica para predecir si un correo es spam o no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
