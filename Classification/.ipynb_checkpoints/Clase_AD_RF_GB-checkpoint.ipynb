{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center> Arboles de Decisión </center> </h1>\n",
    "<p> Los arboles de decisión son estructuras de diagrama de flujo, que consta de nodos (atribituos/caracteristicas), ramas que representan reglas de decisión y nodos finales u hojas que representan un resultado. Un árbol busca seleccionar el mejor atributo a través de una medición heurística (reglas de partición), asignando una puntos de corte del conjunto de datos</p>\n",
    "<p> En este caso, las medidas más populares de selección de variables son: </p>\n",
    "<ul>\n",
    "    <li> Ganancia de información </li>\n",
    "    <li> Indice de Gini </li>\n",
    "    <li> Reducción a la varianza </li>\n",
    "</ul>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El concepto de entriopía\n",
    "Es una medida de incertidumbre o desorden de una variable, utilizado para seleccionar el atributo que particionara la información. Cuanto mayor sea la entriopía, mayor será el contenido de la información, por lo que se busca aquel atributo que discrimine una mayor cantidad de objetos, es decir, que reduzca la entriopía, por lo que reduce la incertidumbre.\n",
    "\n",
    "$$Entropia(S) = \\sum ^{n}_{i=1}-p_{i}log_{2}p_{i}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ganancia de información\n",
    "Es una medida del cambio de entriopía al incluir nuevas reglas de decisión\n",
    "$$GI (S,A) = Entropia(S) - \\sum ^{n}_{i=1}\\frac{|Sv|}{|S|}Entropia(Sv) $$\n",
    "\n",
    "### Algortimo\n",
    "1. Comenzar con todas las instancias de información\n",
    "2. Utilizar la ganancia de información para escoger la primera regla de decisión\n",
    "3. Repetir para cada subconjunto de información\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indice GINI (Impureza GINI)\n",
    "\n",
    "Es una medida que mide la frecuencia en que un elemento al azar sería identificado incorrectamente. Se selecciona un atributo con el índice de GINI más bajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "dataset = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.data\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol = DecisionTreeClassifier(criterion = 'entropy')\n",
    "arbol.fit(X_train,y_train)\n",
    "y_pred = arbol.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_breast_cancer()\n",
    "dataset.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.data\n",
    "y = dataset.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.4)\n",
    "\n",
    "# Por entropy\n",
    "\n",
    "arbol1 = DecisionTreeClassifier(criterion = 'entropy')\n",
    "arbol1.fit(X_train,y_train)\n",
    "y_pred1 = arbol1.predict(X_test)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred1))\n",
    "\n",
    "print(\"Precision\")\n",
    "print(precision_score(y_test,y_pred1))\n",
    "\n",
    "\n",
    "# Por gini\n",
    "\n",
    "arbol2 = DecisionTreeClassifier(criterion = 'gini')\n",
    "arbol2.fit(X_train,y_train)\n",
    "y_pred2 = arbol2.predict(X_test)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred2))\n",
    "\n",
    "print(\"Precision\")\n",
    "print(precision_score(y_test,y_pred2))\n",
    "\n",
    "# print(classification_report(y_test,y_pred2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center> Random Forest </center> </h1>\n",
    "<p> Son una combinación de árboles predictores tal que cada árbol depende de los valores de un vector aleatorio probado independientemente y con la misma distribución para cada uno de estos. Es una modificación sustancial de bagging que construye una larga colección de árboles no correlacionados y luego los promedia.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "dataset = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.data\n",
    "y = dataset.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bosques = RandomForestClassifier(n_estimators=1000)\n",
    "bosques.fit(X_train,y_train)\n",
    "y_pred = bosques.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center> Gradient Boosting </center> </h1>\n",
    "<p> Los clasificadores de Gradient Boosting son un grupo de algoritmos de aprendizaje automático que combinan muchos modelos de aprendizaje débiles para crear un modelo predictivo sólido. Los árboles de decisión generalmente se usan al aumentar el gradiente. Los modelos de aumento de gradiente se están volviendo populares debido a su efectividad en la clasificación de conjuntos de datos complejos. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "dataset = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.data\n",
    "y = dataset.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "\n",
    "for learning_rate in lr_list:\n",
    "    gb_clf = GradientBoostingClassifier(n_estimators=20, learning_rate=learning_rate, max_features=2, max_depth=2, random_state=0)\n",
    "    gb_clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(gb_clf.score(X_train, y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(gb_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf2 = GradientBoostingClassifier(n_estimators=20, learning_rate=0.25, max_features=2, max_depth=2, random_state=0)\n",
    "gb_clf2.fit(X_train, y_train)\n",
    "y_pred = gb_clf2.predict(X_test)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Precision Score\")\n",
    "print(precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center> Maquina soportada de vectores </center> </h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "dataset = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.data\n",
    "y = dataset.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3)\n",
    "\n",
    "clf = LinearSVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Precision Score\")\n",
    "print(precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
